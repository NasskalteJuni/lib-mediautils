var MediaUtilities = (function (exports) {
    'use strict';

    class AudioMixer{

        constructor(){
            this._context = new AudioContext();
            this._out = this._context.createMediaStreamDestination();
            this._in = {};
            const analyzer = this._context.createAnalyser();
            analyzer.maxDecibels;
        }

        get out(){
            return this._out.stream;
        }

        get outputTrack(){
            return this._out.stream.getAudioTracks()[0];
        }

        addStream(mediaStream, id) {
            this._in[id] = this._context.createMediaStreamSource(mediaStream);
            this._rebuildGraph();
        }

        removeStream(mediaStream, id){
            delete this._in[id];
            this._rebuildGraph();
        }

        _rebuildGraph(){
            const inputs = Object.values(this._in);
            if(this._merger) this._merger.disconnect();
            this._merger = this._context.createChannelMerger(inputs.length);
            this._merger.connect(this._context.destination);
            inputs.forEach((input, i) => input.connect(this._merger, 0, i));
        }

    }

    var AudioMixer_1 = AudioMixer;

    class VideoMixingConfiguration {

        constructor(settings) {
            this.__isVideoMixingConfigurationObject = true;
            this.width = 0;
            this.height = 0;
            this._applicable = settings.applicable || true;
            this._positions = settings.positions || [];
            this._background = settings.background || 'rgb(20,20,20)';
            this.paint = settings.paint || null;
            this._priority = settings.priority || 0;
        }

        /**
         * @return boolean
         * */
        applicable(ids){
            if(typeof this._applicable === "function"){
                return this._applicable(ids);
            }else{
                return !!this._applicable;
            }
        }

        /**
         * @return number
         * */
        priority(ids){
            if(this._priority === undefined){
                return 0;
            }else if(typeof this._priority === "function"){
                return this._priority(ids);
            }else{
                return +this._priority;
            }
        }

        /**
         * @return string
         * */
        background(ids){
            if(typeof this._background === "function"){
                return this._background(ids);
            }else{
                return this._background;
            }
        }

        /**
         * @return object
         * */
        positions(id, index, arr){
            if(typeof this._positions === "function"){
                // case: generating function -> let the function handle the creation of position objects
                return this._positions(id, index, arr);
            }else if(this._positions instanceof Array){
                // case: array -> return the array element at given index
                return this._positions[index];
            }else{
                // case: single object -> return a clone of the single object for every stream
                return Object.assign({}, this._positions);
            }
        }
    }

    var VideoMixingConfiguration_1 =VideoMixingConfiguration;

    /**
     * @mixin
     * Handle Video Mixing configurations
     * */
    var _VideoMixingConfigurations = (superclass=Object) => class C extends superclass{

        constructor(){
            super(...arguments);
            this._configChangeHandler = () => {};
            this._streamIds = [];
            this._configs = {};
            this._currentConfigId = null;
        }

        /**
         * set the current number of stream ids
         * @param ids [array] the ids of currently used streams. Needs to be given, since the choice of the current config depends on the number of streams
         * @returns VideoMixingConfiguration the currently used configuration after the stream ids were applied
         * */
        updateStreamIds(ids){
            this._streamIds = ids;
            this._findCurrentConfig();
            return this.currentConfig;
        }

        /**
         * @returns VideoMixingConfiguration the current config. May return null, if there is no current config (because the VideoMixingConfigurationManager was just constructed, for example)
         * */
        get currentConfig(){
            return this.currentConfigId ? this._configs[this._currentConfigId] : null;
        }

        /**
         * @returns string the id of the current config
         * */
        get currentConfigId(){
            return this._currentConfigId;
        }

        /**
         * enforce the given id as current config, independent if it is applicable or not
         * @param id [string] the id of the config to use
         * @throws Error when no config has the given id
         * */
        forceConfig(id){
            if(!this._configs[id]) throw new Error("No config with the id "+id);
            const previousConfigId = this._currentConfigId;
            this._currentConfigId = id;
            this._configChangeHandler(this._configs[id], id, previousConfigId);
        }

        /**
         * @private
         * @static
         * Checks if the given object is a VideoMixingConfiguration or just a plain object that probably should be used as configuration for this
         * @returns VideoMixingConfiguration the given VideoMixingConfiguration or, if none was given, a VideoMixingConfiguration constructed from the given object
         * */
        static _videoMixingConfigurationTypeGuard(configOrPlainObject){
            if(!configOrPlainObject.__isVideoMixingConfigurationObject && !configOrPlainObject instanceof VideoMixingConfiguration_1){
                configOrPlainObject = new VideoMixingConfiguration_1(configOrPlainObject);
            }
            return configOrPlainObject;
        }

        /**
         * adds another config under the given id
         * @param config [VideoMixingConfiguration] a VideoMixingConfiguration (or its settings object)
         * @param id [string] a unique id for the config. Non unique ids will result in unchecked overwriting of the config
         * */
        addConfig(config, id){
            this._configs[id] = C._videoMixingConfigurationTypeGuard(config);
            this._findCurrentConfig();
        }

        /**
         * remove the config with the registered id
         * @param id [string] the id of the config to remove
         * @throws Error when no config with the given id was found
         * */
        removeConfig(id){
            if(!this._configs[id]) throw new Error("No config with the id "+id);
            delete this._configs[id];
            this._findCurrentConfig();
        }

        /**
         * define a function that will be invoked when (and only when) the configuration that should be used currently changes
         * @param cb [function] a function which will retrieve the current configuration, its id, and the previous configuration
         * */
        onConfigChange(cb){
            if(typeof cb !== "function") throw new Error("Callback must be a function");
            this._configChangeHandler = cb;
        }

        /**
         * @private
         * get the config that is applicable AND has the highest priority
         * @return object of structure {id: VideoMixingConfiguration}
         * */
        _findCurrentConfig() {
            let highestApplicableId = null;
            let highestPriority = -Infinity;
            for (let id in this._configs) {
                if(!this._configs.hasOwnProperty(id)) continue;
                const currentConfig = this._configs[id];
                if (currentConfig.applicable(this._streamIds)) {
                    const currentPriority = currentConfig.priority(this._streamIds);
                    if (highestPriority < currentPriority) {
                        highestApplicableId = id;
                        highestPriority = currentPriority;
                    }
                }
            }
            const previousConfigId = this._currentConfigId;
            this._currentConfigId = highestApplicableId;
            if(previousConfigId !== this._currentConfigId) this._configChangeHandler(this.currentConfig, this._currentConfigId, previousConfigId);
        }

    };

    /**
     * @mixin
     * Handle Video Streams
     * */
    var _VideoStreams = (superclass=Object) => class C extends superclass{

        constructor(){
            super(...arguments);
            this._streams = {};
            this._onStreamChangeHandler = () => {};
        }

        /**
         * adds a MediaStream to the managed streams
         * @param stream the MediaStream object to manage
         * @param id the unique identifier used for the mediaStream (useful for removal, custom grids, etc.).
         * */
        addStream(stream, id){
            const helper = document.createElement('video');
            helper.autoplay = true;
            helper.loop = true;
            helper.srcObject = stream;
            helper.onload = () => helper.play();
            this._streams[id] = helper;
            this._onStreamChangeHandler(this.streamIds());
        }

        /**
         * removes a MediaStream from the mixing process
         * @param id the id used to add the media stream
         * @throws Error when there is no stream with the given id
         * */
        removeStream(id){
            if(!this._streams[id]) throw new Error('No stream with id ' + id);
            delete this._streams[id];
            this._onStreamChangeHandler(this.streamIds());
        }

        /**
         * @returns array the list of current streams as their ids
         * */
        streamIds(){
            return Object.keys(this._streams);
        }

        /**
         * @returns HTMLVideoElement of the stream id
         */
        videoByStreamId(id){
            return this._streams[id];
        }

        onStreamChange(cb){
            if(typeof cb !== "function") throw new Error("Callback must be of type function");
            this._onStreamChangeHandler = cb;
        }
    };

    class VideoMixer extends _VideoStreams(_VideoMixingConfigurations()){

        /**
         * create a new video mixer
         * @param config [object] a configuration object
         * @param config.canvas (optional) a canvas element to use for mixing MediaStreams together. Can be null (default, creates new), an element, or a query selector string like 'div.main>#canvas'
         * @param config.fps [int=30] frames per second used for mixing & sampling
         * @param config.startImmediately [boolean=true] tells the mixer to start the mixing as soon as the object is constructed (no waiting for call to .start())
         * @param config.width [int=-1] the width of a newly created canvas, -1 is used to infer the width automatically
         * @param config.height [int=-1] the height of a newly created canvas, -1 is used to infer the width automatically
         * */
        constructor({canvas = null, fps = 30, startImmediately = true, width=-1, height=-1} = {}){
            super();
            this._width = width;
            this._height = height;
            this.fps = fps;
            this._initCanvas(canvas, width, height);
            if(startImmediately) this.start();
            // tie together the video streams and the configurations.
            // changes in the streams require always position recalculation and an update to the config that sometimes changes the current config
            this.onStreamChange(ids => {
                this.updateStreamIds(ids);
                if(this.currentConfig) this._precalculatePositionsAndMatchStreams(this.currentConfig);
            });
            // when the config changes, which does not necessary be due to a change to the used streams
            // (a forceful configuration change, for example)
            // precalculate the positions
            this.onConfigChange(this._precalculatePositionsAndMatchStreams);
        }

        /**
         * @private
         * */
        _precalculatePositionsAndMatchStreams(currentConfig){
            currentConfig.width = this._canvas.width;
            currentConfig.height = this._canvas.height;
            if(!currentConfig.paint){
                const ids = this.streamIds();
                currentConfig.calculatedPositions = ids.map(currentConfig.positions.bind(currentConfig));
                currentConfig.calculatedPositions.sort((a, b) => {
                    const aVal = a.id !== undefined ? 0 : a.index !== undefined ? 1 : 2;
                    const bVal = b.id !== undefined ? 0 : b.index !== undefined ? 1 : 2;
                    const diff = aVal - bVal;
                    if(diff === 0 && a.index !== undefined) return (typeof a.index === "function" ? a(ids) : a) - (typeof b.index === "function" ? b(ids) : b);
                    else return diff;
                });
                currentConfig.calculatedPositions.forEach((pos) => {
                    let id = null;
                    if(pos.id !== undefined){
                        id = typeof pos.id === "function" ? pos.id(ids) : pos.id;
                        if(!this.videoByStreamId(id)) throw new Error('no stream with id '+id);
                        pos.source = this.videoByStreamId(id);
                        pos.assignedId = id;
                    }else if(pos.index !== undefined){
                        let index = typeof pos.index === "function" ? pos.index(ids) : pos.index;
                        if(index > ids.length) throw new Error('not enough streams for index '+index);
                        id = ids[index];
                        pos.source = this.videoByStreamId(id);
                        pos.assignedId = id;
                    }else{
                        if(!ids.length) throw new Error('more position definitions than streams');
                        id = ids[0];
                        pos.source = this.videoByStreamId(id);
                        pos.assignedId = id;
                    }
                    ids.shift();
                });
            }
        }

        /**
         * @private
         * set up a canvas to mix videos according to the optionally given width and height
         * */
        _initCanvas(canvas, width, height){
            if(canvas === null) canvas = document.createElement("canvas");
            this._canvas = typeof canvas === "string" ? document.querySelector(canvas) : canvas;
            if(this._canvas){
                if(this._width !== -1){
                    canvas.width = this._width;
                    canvas.style.width = this._width + 'px';
                }else{
                    this._width = +this._canvas.style.width.replace('px','');
                }
                if(this._height !== -1){
                    canvas.height = this._height;
                    canvas.style.height = this._height + 'px';
                }else{
                    this._height = +this._canvas.style.height.replace('px','');
                }
                this._context = this._canvas.getContext("2d");
                this._context.clearRect(0,0,this._canvas.width,this._canvas.height);
                this._out = this._canvas.captureStream(this.fps);
            }
            if(!this._canvas && typeof canvas === "string") window.addEventListener('load',() => this._initCanvas(canvas, width, height));
        }


        /**
         * mixed output as a MediaStream
         * @return MediaStream
         * */
        get out(){
            return this._out;
        }

        /**
         * mixed output as a MediaStreamTrack of kind video
         * @return MediaStreamTrack
         * */
        get outputTrack(){
            return this._out.getVideoTracks()[0];
        }

        /**
         * @readonly
         * the pixel width of the mixed video
         * */
        get width(){
            return this._width;
        }

        /**
         * @readonly
         * the pixel height of the mixed video
         * */
        get height(){
            return this._height;
        }


        /**
         * can be used to start the mixing process, use this if the option startImmediately was set to false
         * */
        start(){
            this._paintloop = setInterval(this._draw.bind(this), 1000 / this.fps);
        }

        /**
         * stops the video mixing process
         * */
        stop(){
            clearInterval(this._paintloop);
            this._context.clearRect(0,0,this._canvas.width,this._canvas.height);
        }

        /**
         * @private
         * draw the current streams on according to the current config in use on a canvas
         * */
        _draw(){
            if(!this.currentConfig) return;
            const ids = this.streamIds();
            if(this.currentConfig.paint){
                // let the custom paint function handle it
                this.currentConfig.paint(ids, this._canvas, this._context);
            }else{
                this._context.clearRect(0,0,this._width,this._height);
                // check if you have to resolve position functions
                const resolveFn = (v, s) => typeof v === "function" ? v(s) : v;
                this.currentConfig.calculatedPositions.forEach((pos) => {
                    const stats = {width: this.width, height: this.height, id: pos.assignedId};
                    if(pos.source) this._context.drawImage(pos.source, resolveFn(pos.x, stats), resolveFn(pos.y, stats), resolveFn(pos.width, stats), resolveFn(pos.height, stats));
                });
            }
        }

    }

    var VideoMixer_1 = VideoMixer;

    class ConnectionManager{

        /**
         * create a new peer connection manager who handles everything related to transmitting media via RTCPeerConnections
         * */
        constructor({iceServers = [{"urls": "stun:stun1.l.google.com:19302"}], useUnifiedPlan = true} = {}){
            this.peerConnections = {};
            this.iceServers = iceServers;
            this.useUnifiedPlan = useUnifiedPlan;
            this._onIceCandidate = () => {throw new Error('MISSING ICE CANDIDATE HANDLER')};
            this._onOffer = () => {throw new Error('MISSING OFFER HANDLER')};
            this._onTrack = () => {throw new Error('MISSING TRACK HANDLER')};
        }

        /**
         * @readonly
         * the ids of the registered / known users as a list
         * */
        get users(){
            return Object.keys(this.peerConnections);
        }

        /**
         * Get or create a peer connection for the given user.
         * There is always only 1 peer connection per user,
         * if there is none when this method is called, a new one will be created.
         * All relevant handlers will already be bound to the returned peer connection object
         * and the life cycle of it will be also handled by this class, do not try to remove connections manually
         * @param userId [string] for which user a peer connection will be returned
         * @return RTCPeerConnection
         * */
        getPeerConnection(userId){
            if(!this.peerConnections[userId]){
                const rtcConfiguration = {sdpSemantics:  this.useUnifiedPlan ? 'unified-plan' : 'plan-b', iceServers: this.iceServers};
                this.peerConnections[userId] = new RTCPeerConnection(rtcConfiguration);
                this.peerConnections[userId].addEventListener('icecandidate', e => this._handleIceCandidate(userId, e.candidate));
                this.peerConnections[userId].addEventListener('negotiationneeded', () => this._initiateOfferHandshake(userId));
                this.peerConnections[userId].addEventListener('track', e => this._handleTrack(userId, e.track, e.streams));
                this.peerConnections[userId].addEventListener('connectionstatechange', () => this._checkClosed(userId));
                this.peerConnections[userId].addEventListener('iceconnectionstatechange', () => this._disconnectDetection(userId));
                this.peerConnections[userId].addEventListener('signalingstatechange', () => this._checkClosed(userId));
                if(this._onNewPeerConnection) this._onNewPeerConnection(userId, this.peerConnections[userId]);
            }
            return this.peerConnections[userId];
        }


        /**
         * returns all currently active video tracks
         * @param userId [string=null] the user or null for every user
         * @return list all video tracks
         * */
        getAllVideoTracks(userId=null){
            const getVideoTracks = pc => pc.getTransceivers().filter(t => t.active && t.track.kind === "audio" && (t.direction === "sendrecv" || t.direction === "recvonly"));
            return this.userId === null ? Object.values(this.peerConnections).reduce((tracks, c) => tracks.concat(getVideoTracks(c)),[]) : getVideoTracks(this.getPeerConnection(userId).getTransceivers());
        }

        /**
         * returns all currently active audio tracks
         * @param userId [string=null] the user or null for every audio track
         * @return list all audio tracks
         * */
        getAllAudioTracks(userId=null){
            return this.userId === null ? Object.values(this.peerConnections).reduce((tracks, c) => tracks.concat(c.getAudioTracks()),[]) : this.getPeerConnection(userId).getAudioTracks();
        }

        /**
         * returns all currently active video tracks except the ones belonging to the user with the given userId
         * @param userId [string] the user to exclude
         * @return list all video tracks except the ones of the given user
         * */
        getVideoTracksExceptUser(userId){
            const getVideoTracks = pc => pc.getTransceivers().filter(t => t.active && t.track.kind === "video" && (t.direction === "sendrecv" || t.direction === "recvonly"));
            return this.users.filter(u => userId).reduce((tracks, u) => tracks.concat(getVideoTracks(this.peerConnections[u])), []);
        }

        /**
         * returns all currently active video tracks except the ones belonging to the user with the given userId
         * @param userId [string] the user to exclude
         * @return list all video tracks except the ones of the given user
         * */
        getAudioTracksExceptUser(userId){
            const getAudioTracks = pc => pc.getTransceivers().filter(t => t.active && t.track.kind === "audio" && (t.direction === "sendrecv" || t.direction === "recvonly"));
            return this.users.filter(u => userId).reduce((tracks, u) => tracks.concat(getAudioTracks(this.peerConnections[u])), []);
        }

        /**
         * @private
         * handles offer generation when a re-negotiation is needed (because the mcu added a new Transceiver to the connection, for example)
         * triggers the puppeteer onOfferHandler to pass the offer to the node server
         * @param userId [string] which users peer connection needs renegotiation
         * @return object RTCSessionDescription offer
         * */
        async _initiateOfferHandshake(userId){
            const pc = this.getPeerConnection(userId);
            const offer = await pc.createOffer();
            if(pc.signalingState !== "stable") return;
            await pc.setLocalDescription(offer);
            this._onOffer(userId, offer);
            return offer;
        }

        /**
         * call this to handle an offer of a user
         * @param userId [string] the user who sent the offer
         * @param offer [object] an RTCSessionDescription Offer object
         * @returns Promise resolves with an RTCSessionDescription Answer object generated according to the given offer or null in case of a glare situation
         * (MCU and client started an Offer Answer Handshake at the same time and the server made a rollback)
         * */
        async handleOffer(userId, offer){
            const pc = this.getPeerConnection(userId);
            if(pc.signalingState !== "stable"){
                await pc.setLocalDescription({type: 'rollback'});
                await pc.setRemoteDescription(offer);
                return null;
            }else{
                await pc.setRemoteDescription(offer);
                const answer = await pc.createAnswer();
                await pc.setLocalDescription(answer);
                return answer;
            }
        }

        /**
         * call this to handle an answer sdp for a given user
         * @param userId [string] the user who sent the answer
         * @param answer [object] an RTCSessionDescription Answer object
         * @returns Promise resolves when the answer was handled or rejects with an error
         * */
        async handleAnswer(userId, answer){
            const pc = this.getPeerConnection(userId);
            await pc.setRemoteDescription(answer);
        }

        /**
         * @private
         * handle own ice candidates by triggering the given/injected handler of the puppeteer instance,
         * which then takes the candidate from inside puppeteers chromium to the outside node server
         * */
        _handleIceCandidate(userId, candidate){
            if(candidate) this._onIceCandidate(userId, candidate);
        }

        /**
         * register a handle for generated ice candidates
         * @param cb [function] receives as parameters the user id [string] and the ice candidate value [string]
         * */
        onIceCandidate(cb){
            this._onIceCandidate = cb;
        }

        /**
         * register a handle for generated offers
         * @param cb [function] receives as parameters the user id [string] and the offer value [string]
         * */
        onOffer(cb){
            this._onOffer = cb;
        }

        /**
         * register a handle for accessible tracks
         * @param cb The callback function receives the arguments user id [string], track [MediaStreamTrack], streams [array]
         * */
        onTrack(cb){
            if(typeof cb !== "function") throw new Error("ARGUMENT MUST BE A FUNCTION");
            this._onTrackHandle = cb;
        }

        /**
         * @private
         * handle incoming tracks by invoking the onTrackHandle Callback and/or a global onTrackHandleFunction
         * */
        _handleTrack(userId, track, streams){
            this._onTrack(userId, track, streams);
        }


        /**
         * define what you want to do with new peer connections (all handlers are already attached, use for adding Transceivers or similar stuff)
         * @param cb The callback function receives the arguments userId, rtcPeerConnection
         * */
        onNewPeerConnection(cb){
            if(typeof cb !== "function") throw new Error("ARGUMENT MUST BE A FUNCTION");
            this._onNewPeerConnection = cb;
        }

        /**
         * define what you have to do when a peer connection closes (handling the webrtc closing functions will be done automatically)
         * @param cb The callback function receives the arguments userId, rtcPeerConnection
         * */
        onDisconnect(cb){
            if(typeof cb !== "function") throw new Error("ARGUMENT MUST BE A FUNCTION");
            this._onDisconnect = cb;
        }

        /**
         * give ice candidate to MCU
         * @param userId [string] which user sent the given candidate
         * @param candidate [object] an ice candidate received from a user
         * @return Promise resolves when the candidate was added successfully or rejects with the error as reason
         * */
        async addIceCandidate(userId, candidate){
            const pc = this.getPeerConnection(userId);
            return candidate !== null ? pc.addIceCandidate(candidate) : Promise.resolve();
        }


        /**
         * @private
         * check if the connection may be closed due to one peer having no net or a not graceful disconnect (without closing the peer connection)
         * */
        _disconnectDetection(userId){
            const pc = this.getPeerConnection(userId);
            if(pc.iceConnectionState === "disconnected") pc.close();
        }

        /**
         * @private
         * kill closed connections by deleting them
         * */
        _checkClosed(userId){
            const pc = this.getPeerConnection(userId);
            if(pc.connectionState === "closed" || pc.signalingState === "closed"){
                if(this._onDisconnect) this._onDisconnect(userId, pc);
                delete this.peerConnections[userId];
            }
        }
    }

    var ConnectionManager_1 = ConnectionManager;

    class Recorder{

        constructor(stream, {audioOnly = false, startImmediately = true, fileExtension = null} = {}){
            this._fileExtension = fileExtension;
            this._recorder = new MediaRecorder(stream);
            this._data = [];
            this.maxRetrievalTime = 5000;
            if(startImmediately) this._recorder.start();
            else this.start = () => this._recorder.start();
        }

        _createFileName(){
            const name = "recording";
            const date = new Date().toISOString();
            const extension = this._fileExtension || (this._recorder.mimeType.startsWith('audio') ? '.ogg' : '.mp4');
            return date + '_' + name + extension;
        }

        toFile(){
            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => clearTimeout(timeout) || reject(new Error('Retrieving data took to long')), this.maxRetrievalTime);
                this._recorder.ondataavailable = e => {
                    if(e.data.size === 0) reject(new Error('Empty Recorder or cannot access recorded data at the moment'));
                    this._data.push(e.data);
                    const blob = new Blob(this._data, this._recorder.mimeType);
                    resolve(new File([blob], this._createFileName()));
                };
                this._recorder.onerror = err => reject(err);
                this._recorder.requestData();
            });
        }

    }

    var Recorder_1 = Recorder;

    class SpeechDetection{

        /**
         * creates a speech (or noise) detector,
         * which checks which given Streams are currently loud enough for typical human speech
         * (most parts of this were directly taken or inspired by hark.js https://github.com/latentflip/hark/)
         * @param config [object]
         * @param config.treshold [number=-70] a dBFS measure. Positive numbers will be made negative
         * @param config.samplingInterval [number=100] milliseconds between samples. Higher sample rate equals earlier detection but also more cpu cost
         * @param config.smoothingConstant [number=0.1] smoothes input to avoid peaks, set values with caution
         * @param config.requiredSamplesForSpeech [number=5] on how many consecutive samples must be a dBFS value over treshold to be considered speech
         * @param config.debug [boolean=false] logging on events if true
         * */
        constructor({threshold=-70, samplingInterval=100, smoothingConstant=0.1, requiredSamplesForSpeech=5, debug=false} = {}){
            this._smoothingConstant = 0.1;
            this._samplingInterval = 100; //ms
            this._treshold = -Math.abs(threshold);
            this.requiredSamplesForSpeech = 3;
            this._in = {};
            this._out = {};
            this._context = new AudioContext();
            this._onSpeechStartByStream = () => {};
            this._onSpeechEndByStream = () => {};
            this._onSpeechStart = () => {};
            this._onSpeechEnd = () => {};
            this._onSpeakerChange = () => {};
            this._lastSpeakers = [];
            this._silence = true;
            this._debug = debug;
            this._analyzerLoop = setInterval(() => {
                Object.keys(this._in).forEach(this._processForEachUser.bind(this));
                const currentSpeakers = Object.keys(this._out).reduce((speakers, id) => this._getStatsFor(id).speaking ? speakers.concat(id) : speakers, []).sort();
                const currentLength = currentSpeakers.length;
                const lastLength = this._lastSpeakers.length;
                const change = currentLength !== lastLength || !currentSpeakers.reduce((allSame, id, i) => currentSpeakers[i] === this._lastSpeakers[i] ? allSame : false, true);
                const speechEnd = currentLength === 0 && lastLength > 0;
                const speechStart = currentLength > 0 && lastLength === 0;
                if(speechStart){
                    if(this._debug) console.log('speech start');
                    this._onSpeechStart(currentSpeakers);
                    this._silence = false;
                }
                if(speechEnd){
                    if(this._debug) console.log('speech end');
                    this._onSpeechEnd(currentSpeakers);
                    this._silence = true;
                }
                if(change){
                    if(this._debug) console.log('speakers changed', currentSpeakers, this._lastSpeakers);
                    this._onSpeakerChange(currentSpeakers, this._lastSpeakers.slice());
                }
                this._lastSpeakers = currentSpeakers;
            }, this._samplingInterval);
        }

        /**
         * @param v [number] decibel (dBFS) value set as treshold for sound, non negative values will be made negative
         * */
        set treshold(v){
            this.treshold = -Math.abs(v);
        }

        /**
         * the current treshold for a stream to be considered not silent
         * */
        get treshold(){
            return this.treshold;
        }

        /**
         * @readonly
         * current stats by each registered stream
         * */
        get out(){
            return Object.assign({}, this._out);
        }

        /**
         * @readonly
         * if all registered streams are silent
         * */
        get silence(){
            return this._silence;
        }

        /**
         * @readonly
         * a list of the latest speakers (empty when no one spoke since the last sample)
         * */
        get speakers(){
            return this._lastSpeakers
        }

        _getStatsFor(id){
            if(!this._out[id]) this._out[id] = {consecutiveSamplesOverTreshold: 0, speaking: false, current: null};
            return this._out[id];
        }

        /**
         * add a stream to the current detection process
         * @param stream [MediaStream] a media stream to add (not checked, if it contains audio tracks at the current time or not)
         * @param id an id to reference the stream and its results
         * */
        addStream(stream, id){
            const analyzer = this._context.createAnalyser();
            analyzer.fftSize = 512;
            analyzer.smoothingTimeConstant = this._smoothingConstant;
            const fftBins = new Float32Array(analyzer.frequencyBinCount);
            const source = this._context.createMediaStreamSource(stream);
            source.connect(analyzer);
            this._in[id] = {analyzer, fftBins, source, stream};
        }

        _analyzeVolume(analyzer, fftBins){
            analyzer.getFloatFrequencyData(fftBins);
            // set max as smallest value and min as biggest value so that any other value will overwrite them
            let minVolume = 0; // highest dBFS
            let maxVolume = -Infinity; // silence
            let average = 0;
            let count = 0;
            fftBins.forEach(f => {
                if(f > maxVolume) maxVolume = f;
                if(f < minVolume) minVolume = f;
                average+=f;
                count++;
            });
            average/=count;
            return {minVolume, maxVolume, average}
        }

        _processForEachUser(id){
            const output = this._getStatsFor(id);
            const stats = this._analyzeVolume(this._in[id].analyzer, this._in[id].fftBins);
            output.current = stats;
            if(stats.maxVolume > this._treshold){
                output.consecutiveSamplesOverTreshold++;
                if(output.consecutiveSamplesOverTreshold > this.requiredSamplesForSpeech){
                    output.speaking = true;
                    this._onSpeechStartByStream(id);
                }
            }else{
                output.consecutiveSamplesOverTreshold = 0;
                if(output.speaking){
                    output.speaking = false;
                    this._onSpeechEndByStream(id);
                }
            }
        }

        static _checkCb(cb){
            if(typeof cb !== "function") throw new Error('Callback must be a function');
        }

        /**
         * callback triggers when any stream switches from silent to speaking,
         * the id of the stream is given to the callback function
         * @param cb [function]
         * */
        onSpeechStartByStream(cb){
            SpeechDetection._checkCb(cb);
            this._onSpeechStartByStream = cb;
        }

        /**
         * callback triggers when any stream switches from speaking to silent,
         * the id of the stream is given to the callback function
         * @param cb [function]
         * */
        onSpeechEndByStream(cb){
            SpeechDetection._checkCb(cb);
            this._onSpeechEndByStream = cb;
        }

        /**
         * callback triggers, when no one was speaking and now one stream went from silence to speaking.
         * The callback receives a list of ids of streams which are not silent any more
         * @param cb [function]
         * */
        onSpeechStart(cb){
            SpeechDetection._checkCb(cb);
            this._onSpeechStart = cb;
        }

        /**
         * callback triggers, when the last not silent stream goes silent
         * @param cb [function]
         * */
        onSpeechEnd(cb){
            SpeechDetection._checkCb(cb);
            this._onSpeechEnd = cb;
        }

        /**
         * callback triggers, as soon as another stream goes from silent to speaking or vice versa
         * */
        onSpeakerChange(cb){
            SpeechDetection._checkCb(cb);
            this._onSpeakerChange = cb;
        }
    }

    var SpeechDetection_1 = SpeechDetection;

    class Transcriber {

        /**
         * Create a transcriber for a given track who allows you to set up the peer connection with the given quality transcription
         * */
        constructor(trackOrKind, trackSettings = {}) {
            this._trackOrKind = trackOrKind;
            this._trackSettings = trackSettings;
            this._kind = typeof trackOrKind === "string" ? trackOrKind : trackOrKind.kind;
            this._qualities = {
                full: {
                    video: {},
                    audio: {},
                },
                high: {
                    video: {
                        "maxFramerate": 60
                    },
                    audio: {}
                },
                medium: {
                    video: {
                        "maxFramerate": 30
                    },
                    audio: {},
                },
                low: {
                    video: {
                        "maxFramerate": 15,
                        "scaleResolutionDownBy": 2
                    },
                    audio: {},
                },
                micro: {
                    video: {
                        "maxFramerate": 10,
                        "scaleResolutionDownBy": 4,
                        "maxBitrate": 8 * 1024 * 2,
                    },
                    audio: {
                        "maxBitrate": 8 * 1024 * 4,
                        // dtx: true // currently poor browser support, only moz ff >= v46
                    }
                }
            };
        }

        _mergeRtpSettingsForTrack(rtpOptions){
            const trackSettingsCopy = Object.assign({}, this._trackSettings);
            if(!trackSettingsCopy.sendEncodings){
                trackSettingsCopy.sendEncodings = [rtpOptions];
            }else{
                trackSettingsCopy.sendEncodings.forEach(encoding => {
                    Object.keys(rtpOptions).forEach(key => {
                        console.log(key, key in encoding);
                        if (!(key in encoding)) encoding[key] = rtpOptions[key];
                    });
                });
            }
            return trackSettingsCopy;
        }

        /**
         * returns the track and the options to pass to addTransceiver.
         * You may use this like peerConnection.addTransceiver(...myTranscriber.transcribe('medium'));
         * @param quality [string] one of the quality settings of the transcriber (by default full, high, medium, low, micro)
         * @returns [trackOrKind, settings]
         * */
        transcribe(quality){
            quality = quality.toLowerCase();
            if(Object.keys(this._qualities).indexOf(quality) === -1) throw new Error('Unsupported quality option');
            return [this._trackOrKind, this._mergeRtpSettingsForTrack(this._qualities[quality][this._kind])];
        }

    }

    var Transcriber_1 = Transcriber;

    /**
     * @private
     * @param n [UInt] the positive integer to factor
     * @return array of tuples of factoring numbers, unique (only a,b but not a,b and b,a) and sorted biggest factors first
     * */
    function factors(n){
        if(n === null || n === undefined || isNaN(n)) throw new Error('Invalid argument, n must be a number but is ' + n);
        if(n === 0 || n === 1) return [[n, n]];
        const factorDict = {};
        // honestly, there is no need for factoring algorithms like rho,
        // n will be less than 30, one could even hard-code the results...
        for(let i = 1; i <= Math.floor(n/2); i++){
            const isDivisor = n%i === 0;
            if(isDivisor){
                if(!factorDict[i]) factorDict[n/i] = i;
            }
        }
        return Object.keys(factorDict).map(k => [factorDict[k],+k]);
    }

    /**
     * Places Streams in a grid
     * */
    class Grid extends VideoMixingConfiguration_1{

        /**
         * Creates a grid of videos, which works best for square numbers but also for numbers which can be factored by a and b with |a-b| <= 2
         * Everything else seemed to look bad
         * @param priority [int=0]
         * @param applicable [function=differenceBetweenTwoBiggestFactors(ids.length) <= 2]
         * */
        constructor(priority = 0, applicable = ids =>Math.abs(factors(ids.length)[0][1]-factors(ids.length)[0][0]) <= 2){
            super({
                applicable,
                priority: 0,
                positions: function(id, index, arr){
                    const [rows, columns] = factors(arr.length)[0];
                    const frameWidth = this.width/columns;
                    const frameHeight = this.height/rows;
                    return {
                        x: (index % columns) * frameWidth,
                        y: ~~(index / columns) * frameHeight,
                        width: frameWidth,
                        height: frameHeight
                    };
                }
            });
        }
    }

    var Grid_1 = Grid;

    /**
     * Places 1 video in the middle and the other 4s in a grid around it
     * */
    class Middle extends VideoMixingConfiguration_1{

        /**
         * create a grid of streams where one stream (the last one) is in the middle
         * @param priority [int=0]
         * */
        constructor(priority = 0){
            super({
                priority,
                applicable: videos => videos.length === 5,
                positions: [
                    // since we cannot refer to 'this' to get width and height at the moment,
                    // we pass functions for values that will receive a stats object with width, height and id of the current stream.
                    // these functions are calculated just before the painting happens and can be used for dynamic updates on each frame
                    // 2x2 grid
                    {x: 0, y: 0, width: s => s.width/2, height: s => s.height/2},
                    {x: s => s.width/2, y: 0, width: s => s.width/2, height: s => s.height/2},
                    {x: 0, y: s => s.height/2, width: s => s.width/2, height: s => s.height/2},
                    {x: s => s.width/2, y: s => s.height/2, width: s => s.width/2, height: s => s.height/2},
                    // last video in the middle above all
                    {x: s => s.width/4, y: s => s.height/4, width: s => s.width/2, height: s => s.height/2}
                ]
            });
        }
    }

    var Middle_1 = Middle;

    /**
     * Places streams beside each other
     * */
    class Line extends VideoMixingConfiguration_1{

        /**
         * creates a new Line Mixing config for less than 3 persons
         * @param priority [int=0]
         * @param applicable [ids => ids.length < 3]
         * */
        constructor(priority = 0, applicable = ids => ids.length < 3){
            super({
                applicable,
                priority,
                positions: function(id, index, arr){
                    return {
                        x: (this.width/arr.length) * index,
                        y: 0,
                        width: this.width/arr.length,
                        height: this.height
                    }
                }
            });
        }
    }

    var Line_1 = Line;

    var MediaServerUtilities = {
        VideoMixer: VideoMixer_1,
        AudioMixer: AudioMixer_1,
        Transcriber: Transcriber_1,
        ConnectionManager: ConnectionManager_1,
        Recorder: Recorder_1,
        SpeechDetection: SpeechDetection_1,
        VideoMixingConfiguration: VideoMixingConfiguration_1,
        VideoMixingConfigurations: {
            Grid: Grid_1,
            Middle: Middle_1,
            Line: Line_1
        }
    };
    var MediaServerUtilities_1 = MediaServerUtilities.VideoMixer;
    var MediaServerUtilities_2 = MediaServerUtilities.AudioMixer;
    var MediaServerUtilities_3 = MediaServerUtilities.Transcriber;
    var MediaServerUtilities_4 = MediaServerUtilities.ConnectionManager;
    var MediaServerUtilities_5 = MediaServerUtilities.Recorder;
    var MediaServerUtilities_6 = MediaServerUtilities.SpeechDetection;
    var MediaServerUtilities_7 = MediaServerUtilities.VideoMixingConfiguration;
    var MediaServerUtilities_8 = MediaServerUtilities.VideoMixingConfigurations;

    exports.AudioMixer = MediaServerUtilities_2;
    exports.ConnectionManager = MediaServerUtilities_4;
    exports.Recorder = MediaServerUtilities_5;
    exports.SpeechDetection = MediaServerUtilities_6;
    exports.Transcriber = MediaServerUtilities_3;
    exports.VideoMixer = MediaServerUtilities_1;
    exports.VideoMixingConfiguration = MediaServerUtilities_7;
    exports.VideoMixingConfigurations = MediaServerUtilities_8;
    exports.default = MediaServerUtilities;

    return exports;

}({}));
//# sourceMappingURL=bundle.min.js.map
